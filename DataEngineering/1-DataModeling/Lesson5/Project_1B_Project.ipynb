{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESS THE DATA FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hynso/Documents/Learning/Udacity/DataEngineering/1-DataModeling/Lesson5\n"
     ]
    }
   ],
   "source": [
    "# checking the current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get the current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    # join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# For every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "    # Read csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # Create a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "        # Extract each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# Create a smaller event data csv file called event_datafile_new.csv \n",
    "# that will be used to insert data into the Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                     'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in the csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Apache Cassandra coding portion of your project. \n",
    "\n",
    "## The event_datafile_new.csv contains the following columns: \n",
    "\n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the `event_datafile_new.csv` after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cluster object and connect to it with a \"session\"\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1'])\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a keyspace called `udacity`\n",
    "try:\n",
    "    session.execute(\n",
    "        \"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS udacity\n",
    "        WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\n",
    "        \"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working keyspace to the freshly made `udacity` keyspace\n",
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create queries to ask the following three questions of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1: Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "Query Description: Here the `session_id` and `item_in_session` fields will be used in the WHERE clause, so these two fields should (1) make up the composite primary key and (2) make up the composite partition key. As a composite primary key, these fields will allow each record in the table to be uniquely identified. They weren't originally part of a composite partition key, but I received feedback that they should be. However, I don't fully understand the rationale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table for this query\n",
    "\n",
    "query = \\\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS artist_song_table (\n",
    "      session_id      INT, -- partition key column 0\n",
    "      item_in_session INT, -- partition key column 1\n",
    "      artist_name     TEXT,\n",
    "      song_title      TEXT,\n",
    "      song_length     DOUBLE,\n",
    "      PRIMARY KEY ((session_id, item_in_session))\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Insert the appropriate data based on the data model\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "query = \\\n",
    "    \"\"\"\n",
    "    INSERT INTO artist_song_table (\n",
    "      session_id,\n",
    "      item_in_session,\n",
    "      artist_name,\n",
    "      song_title,\n",
    "      song_length\n",
    "    )\n",
    "    VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:     \n",
    "        session.execute(\n",
    "          query, \n",
    "          (int(line[8]), int(line[3]), line[0], line[9], float(line[5]))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>artist_name</th>\n",
       "      <th>song_title</th>\n",
       "      <th>song_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Faithless</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>495.3073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do a SELECT to verify the data model and \n",
    "# that correct data has been inserted into the table\n",
    "\n",
    "query = \\\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "      artist_name, \n",
    "      song_title, \n",
    "      song_length \n",
    "    FROM artist_song_table \n",
    "    WHERE\n",
    "      session_id=338 AND\n",
    "      item_in_session=4\n",
    "    \"\"\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "HTML(pd.DataFrame(rows).to_html(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "Query Description: Here the `user_id` and `session_id` fields will be used in the WHERE clause, so these two fields should (1) make up _**part**_ of the composite primary key and (2) make up the composite partition key. In addition to `user_id` and `session_id`, the `item_in_session` field will be included as the final part of the composite primary key. As a composite primary key, these three fields will allow each record in the table to be uniquely identified. As a composite partition key, both `user_id` and `session_id` will allow partitions to be appropriately sized for performant queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table for this query\n",
    "\n",
    "query = \\\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS artist_song_user_table (\n",
    "      user_id         INT,  -- partition key column 0\n",
    "      session_id      INT,  -- partition key column 1\n",
    "      item_in_session INT,  -- clustering column 0\n",
    "      artist_name     TEXT,\n",
    "      song_title      TEXT,\n",
    "      first_name      TEXT,\n",
    "      last_name       TEXT,\n",
    "      PRIMARY KEY ((user_id, session_id), item_in_session)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the appropriate data based on the data model\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "query = \\\n",
    "    \"\"\"\n",
    "    INSERT INTO artist_song_user_table (\n",
    "      user_id,\n",
    "      session_id,\n",
    "      item_in_session,\n",
    "      artist_name,\n",
    "      song_title,\n",
    "      first_name,\n",
    "      last_name\n",
    "    )\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        session.execute(\n",
    "          query, \n",
    "          (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>artist_name</th>\n",
       "      <th>song_title</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>item_in_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Down To The Bone</td>\n",
       "      <td>Keep On Keepin' On</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Three Drives</td>\n",
       "      <td>Greece 2000</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sebastien Tellier</td>\n",
       "      <td>Kilometer</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Lonnie Gordon</td>\n",
       "      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio Edit)</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do a SELECT to verify the data model and \n",
    "# that correct data has been inserted into the table\n",
    "\n",
    "query = \\\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "      artist_name, \n",
    "      song_title, \n",
    "      first_name,\n",
    "      last_name,\n",
    "      item_in_session\n",
    "    FROM artist_song_user_table \n",
    "    WHERE \n",
    "      user_id=10 AND\n",
    "      session_id=182\n",
    "    \"\"\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "HTML(pd.DataFrame(rows).to_html(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "Query Description: Here the `song_title` field will be used in the WHERE clause, so this field should (1) make up _**part**_ of the composite primary key and (2) be the partition key. In addition to `song_title`, the `user_id` field will be included as the final part of the composite primary key. As a composite primary key, these two fields will allow each record in the table to be uniquely identified. A reviewer recommended that both fields make up the composite partition key, but implementing this resulted in the following error message:\n",
    "\n",
    "```\n",
    "Error from server: code=2200 [Invalid query] \n",
    "message=\"Partition key parts: user_id must be restricted as other parts are\"\n",
    "```\n",
    "\n",
    "Therefore, only the `song_title` field has been retained as the sole partition key column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the table for this query\n",
    "\n",
    "query = \\\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS user_song_table (\n",
    "      song_title      TEXT, -- partition key column 0\n",
    "      user_id         INT,  -- clustering column 0\n",
    "      first_name      TEXT,\n",
    "      last_name       TEXT,\n",
    "      PRIMARY KEY (song_title, user_id)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the appropriate data based on the data model\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "query = \\\n",
    "    \"\"\"\n",
    "    INSERT INTO user_song_table (\n",
    "      song_title,\n",
    "      user_id,\n",
    "      first_name,\n",
    "      last_name\n",
    "    )\n",
    "    VALUES (%s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        session.execute(\n",
    "          query, \n",
    "          (line[9], int(line[10]), line[1], line[4])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>Lynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tegan</td>\n",
       "      <td>Levine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sara</td>\n",
       "      <td>Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do a SELECT to verify the data model and \n",
    "# that correct data has been inserted into the table\n",
    "\n",
    "query = \\\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "      first_name,\n",
    "      last_name\n",
    "    FROM user_song_table \n",
    "    WHERE song_title='All Hands Against His Own'\n",
    "    \"\"\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "HTML(pd.DataFrame(rows).to_html(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first table\n",
    "query = \"DROP TABLE IF EXISTS artist_song_table\"\n",
    "\n",
    "try:\n",
    "    res = session.execute(query)\n",
    "except Execption as e:\n",
    "    print(e)\n",
    "    \n",
    "# Drop the second table\n",
    "query = \"DROP TABLE IF EXISTS artist_song_user_table\"\n",
    "\n",
    "try:\n",
    "    res = session.execute(query)\n",
    "except Execption as e:\n",
    "    print(e)\n",
    "\n",
    "# Drop the third table\n",
    "query = \"DROP TABLE IF EXISTS user_song_table\"\n",
    "\n",
    "try:\n",
    "    res = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
